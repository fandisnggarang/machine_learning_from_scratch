{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "data = fetch_openml(data_id=1590, as_frame=True)\n",
    "\n",
    "X = data.data\n",
    "y = data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>Private</td>\n",
       "      <td>226802</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>89814</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Farming-fishing</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>Local-gov</td>\n",
       "      <td>336951</td>\n",
       "      <td>Assoc-acdm</td>\n",
       "      <td>12</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Protective-serv</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44</td>\n",
       "      <td>Private</td>\n",
       "      <td>160323</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>7688</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>103497</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  workclass  fnlwgt     education  education-num      marital-status  \\\n",
       "0   25    Private  226802          11th              7       Never-married   \n",
       "1   38    Private   89814       HS-grad              9  Married-civ-spouse   \n",
       "2   28  Local-gov  336951    Assoc-acdm             12  Married-civ-spouse   \n",
       "3   44    Private  160323  Some-college             10  Married-civ-spouse   \n",
       "4   18        NaN  103497  Some-college             10       Never-married   \n",
       "\n",
       "          occupation relationship   race     sex  capital-gain  capital-loss  \\\n",
       "0  Machine-op-inspct    Own-child  Black    Male             0             0   \n",
       "1    Farming-fishing      Husband  White    Male             0             0   \n",
       "2    Protective-serv      Husband  White    Male             0             0   \n",
       "3  Machine-op-inspct      Husband  Black    Male          7688             0   \n",
       "4                NaN    Own-child  White  Female             0             0   \n",
       "\n",
       "   hours-per-week native-country  class  \n",
       "0              40  United-States  <=50K  \n",
       "1              50  United-States  <=50K  \n",
       "2              40  United-States   >50K  \n",
       "3              40  United-States   >50K  \n",
       "4              30  United-States  <=50K  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "income_data = pd.concat([X, y], axis= 1)\n",
    "income_data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data NA:\n",
      "age                  0\n",
      "workclass         2799\n",
      "fnlwgt               0\n",
      "education            0\n",
      "education-num        0\n",
      "marital-status       0\n",
      "occupation        2809\n",
      "relationship         0\n",
      "race                 0\n",
      "sex                  0\n",
      "capital-gain         0\n",
      "capital-loss         0\n",
      "hours-per-week       0\n",
      "native-country     857\n",
      "class                0\n",
      "dtype: int64\n",
      "\n",
      "Data shape   : (48842, 15)\n",
      "\n",
      "Data Duplikat: 52\n"
     ]
    }
   ],
   "source": [
    "print(f'Data NA:')\n",
    "print(income_data.isna().sum())\n",
    "print()\n",
    "print(f'Data shape   : {income_data.shape}')\n",
    "print()\n",
    "print(f'Data Duplikat: {income_data.duplicated().sum()}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sepertinya, data yang NA dan Duplikat bisa dihapus saja, mengingat perbandingan antara data NA dan data Duplikat dengan data keseluruhan sangat besar. \n",
    "\n",
    "Selain itu feature 'fnlwgt' dihapus karena dianggap tidak relevan. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data setelah NA, duplikat, dan irrelevant feature di-drop: (45175, 14)\n"
     ]
    }
   ],
   "source": [
    "income_data = income_data.drop_duplicates(keep='last').dropna()\n",
    "income_data = income_data.drop(columns = 'fnlwgt')\n",
    "\n",
    "print(f'Data setelah NA, duplikat, dan irrelevant feature di-drop: {income_data.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = income_data.drop('class', axis=1)\n",
    "y = income_data['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class\n",
       "<=50K    0.752031\n",
       ">50K     0.247969\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Terlihat bahwa terjadi proporsi kelas yang tidak seimbang. Diperlukan perlakuan khusus saat splitting data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling & Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape after sampling: (5000, 13)\n",
      "y shape after sampling: (5000,)\n"
     ]
    }
   ],
   "source": [
    "num_samples = 5000\n",
    "X = X.sample(n=num_samples, random_state=42)\n",
    "y = y.loc[X.index]\n",
    "\n",
    "print(f'X shape after sampling: {X.shape}')\n",
    "print(f'y shape after sampling: {y.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sampling dilakukan untuk menyederhanakan dataset agar proses modeling tidak memakan waktu terlalu lama. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X train shape: (4000, 13)\n",
      "y train shape: (4000,)\n",
      "X test shape : (500, 13)\n",
      "y test shape : (500,)\n",
      "X valid shape: (500, 13)\n",
      "y valid shape: (500,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "X_train, X_not_train, y_train, y_not_train = train_test_split(X, y, test_size=0.2, random_state=123, stratify=y)\n",
    "\n",
    "X_valid, X_test, y_valid, y_test           = train_test_split(X_not_train, y_not_train, test_size=0.5, random_state=123, stratify=y_not_train)\n",
    "\n",
    "print('X train shape:', X_train.shape)\n",
    "print('y train shape:', y_train.shape)\n",
    "print('X test shape :', X_test.shape)\n",
    "print('y test shape :', y_test.shape)\n",
    "print('X valid shape:', X_valid.shape)\n",
    "print('y valid shape:', y_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = []\n",
    "cat_features = []\n",
    "\n",
    "for i in X_train.columns:\n",
    "    if pd.api.types.is_numeric_dtype(X_train[i]):  # Check if the column is numeric\n",
    "        num_features.append(i)\n",
    "    else:\n",
    "        cat_features.append(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['age', 'education-num', 'capital-gain', 'capital-loss', 'hours-per-week']\n"
     ]
    }
   ],
   "source": [
    "print(num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'native-country']\n"
     ]
    }
   ],
   "source": [
    "print(cat_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "workclass: 7\n",
      "education: 16\n",
      "marital-status: 7\n",
      "occupation: 14\n",
      "relationship: 6\n",
      "race: 5\n",
      "sex: 2\n",
      "native-country: 40\n"
     ]
    }
   ],
   "source": [
    "for i in cat_features: \n",
    "    n = len(np.unique(X[i]))\n",
    "    print(f'{i}: {n}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "encoded_y_train = label_encoder.fit_transform(y_train)\n",
    "encoded_y_valid = label_encoder.transform(y_valid)\n",
    "encoded_y_test  = label_encoder.transform(y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47277    <=50K\n",
       "48804    <=50K\n",
       "38721    <=50K\n",
       "24852    <=50K\n",
       "38819    <=50K\n",
       "         ...  \n",
       "15106    <=50K\n",
       "4364     <=50K\n",
       "31234    <=50K\n",
       "26284     >50K\n",
       "26871     >50K\n",
       "Name: class, Length: 4000, dtype: category\n",
       "Categories (2, object): ['<=50K', '>50K']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 1, 1])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48022    <=50K\n",
       "46640    <=50K\n",
       "26311    <=50K\n",
       "18081    <=50K\n",
       "31101    <=50K\n",
       "         ...  \n",
       "11852    <=50K\n",
       "6940     <=50K\n",
       "8045     <=50K\n",
       "1220     <=50K\n",
       "2542     <=50K\n",
       "Name: class, Length: 500, dtype: category\n",
       "Categories (2, object): ['<=50K', '>50K']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
       "       0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0,\n",
       "       1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0,\n",
       "       0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
       "       1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1,\n",
       "       0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0,\n",
       "       0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_y_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36220    <=50K\n",
       "46290    <=50K\n",
       "37900    <=50K\n",
       "47785    <=50K\n",
       "18374     >50K\n",
       "         ...  \n",
       "4492      >50K\n",
       "1117     <=50K\n",
       "16624    <=50K\n",
       "12809    <=50K\n",
       "45883    <=50K\n",
       "Name: class, Length: 500, dtype: category\n",
       "Categories (2, object): ['<=50K', '>50K']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1,\n",
       "       1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0,\n",
       "       0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0,\n",
       "       0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0,\n",
       "       0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0,\n",
       "       0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Label Encoder mengubah: \n",
    "a. <=50K menjadi 0 \n",
    "b. > 50K menjadi 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling & One Hot Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer \n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "cat_transformer = OneHotEncoder(handle_unknown='ignore')\n",
    "num_transformer = StandardScaler() \n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', cat_transformer, cat_features),\n",
    "        ('num', num_transformer, num_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor)\n",
    "])\n",
    "\n",
    "X_train_processed = pipeline.fit_transform(X_train)\n",
    "X_valid_processed = pipeline.transform(X_valid)\n",
    "X_test_processed  = pipeline.transform(X_test)\n",
    "\n",
    "X_train_processed = X_train_processed.toarray() if hasattr(X_train_processed, 'toarray') else X_train_processed \n",
    "X_valid_processed = X_valid_processed.toarray() if hasattr(X_valid_processed, 'toarray') else X_valid_processed \n",
    "X_test_processed  = X_test_processed.toarray() if hasattr(X_test_processed, 'toarray') else X_test_processed \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Karena adaboost menggunakan data target -1 dan 1, maka y perlu dikonversikan dari 0 dan 1 menjadi -1 dan 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 0 to -1 for AdaBoost\n",
    "ab_encoded_y_train = 2 * encoded_y_train - 1\n",
    "ab_encoded_y_valid = 2 * encoded_y_valid - 1\n",
    "ab_encoded_y_test  = 2 * encoded_y_test  - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1  1]\n",
      "[-1  1]\n",
      "[-1  1]\n"
     ]
    }
   ],
   "source": [
    "print(np.unique(ab_encoded_y_train))\n",
    "print(np.unique(ab_encoded_y_valid))\n",
    "print(np.unique(ab_encoded_y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom model\n",
    "from Logistic_Regression import Logistic_Regression\n",
    "from KNN_Classifier import KNearest_Neighbor_Classifier\n",
    "from SVM_Classifier import SVM_Classifier\n",
    "\n",
    "from DecTree_Classifier import Decision_Tree_Classifier\n",
    "from RandomForest_Classifier import Random_Forest_Classifier\n",
    "from AdaBoost_Classifier import Adaboost_Classifier\n",
    "\n",
    "# sklearn model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC \n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "# accuracy metric \n",
    "def accuracy(y_true, y_pred):\n",
    "    return np.sum(y_true == y_pred) / len(y_true)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom Logistic Regression Accuracy Valid : 0.808\n",
      "Custom Logistic Regression Accuracy Test  : 0.816\n",
      "\n",
      "SKLearn Logistic Regression Accuracy Valid: 0.834\n",
      "SKLearn Logistic Regression Accuracy Test : 0.848\n"
     ]
    }
   ],
   "source": [
    "# Custom Logistic Regression Classifier\n",
    "lre_cus = Logistic_Regression(learning_rate=0.01, iters_number=1000)\n",
    "lre_cus.fit(X_train_processed, encoded_y_train)\n",
    "\n",
    "# Sklearn Logistic Regression Classifier\n",
    "lre_skl = LogisticRegression()\n",
    "lre_skl.fit(X_train_processed, encoded_y_train)\n",
    "\n",
    "# Predictions\n",
    "cus_y_pred_valid = lre_cus.predict(X_valid_processed)\n",
    "cus_y_pred_test  = lre_cus.predict(X_test_processed)\n",
    "\n",
    "skl_y_pred_valid = lre_skl.predict(X_valid_processed)\n",
    "skl_y_pred_test  = lre_skl.predict(X_test_processed)\n",
    "\n",
    "# Accuracy\n",
    "cus_acc_valid = accuracy(encoded_y_valid, cus_y_pred_valid)\n",
    "cus_acc_test  = accuracy(encoded_y_test, cus_y_pred_test)\n",
    "\n",
    "skl_acc_valid = accuracy(encoded_y_valid, skl_y_pred_valid)\n",
    "skl_acc_test  = accuracy(encoded_y_test, skl_y_pred_test)\n",
    "\n",
    "# Print Results\n",
    "print('Custom Logistic Regression Accuracy Valid :', cus_acc_valid)\n",
    "print('Custom Logistic Regression Accuracy Test  :', cus_acc_test)\n",
    "print()\n",
    "print('SKLearn Logistic Regression Accuracy Valid:', skl_acc_valid)\n",
    "print('SKLearn Logistic Regression Accuracy Test :', skl_acc_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### KNearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom  KNN Classifier Accuracy Valid: 0.812\n",
      "Custom  KNN Classifier Accuracy Test : 0.846\n",
      "\n",
      "SKLearn KNN Classifier Accuracy Valid: 0.818\n",
      "SKLearn KNN Classifier Accuracy Test : 0.844\n"
     ]
    }
   ],
   "source": [
    "# Custom KNN Classifier\n",
    "knn_cus = KNearest_Neighbor_Classifier(k_value=5, distance_metric='manhattan')\n",
    "knn_cus.fit(X_train_processed, encoded_y_train)\n",
    "\n",
    "# Sklearn KNN Classifier\n",
    "knn_skl = KNeighborsClassifier()\n",
    "knn_skl.fit(X_train_processed, encoded_y_train)\n",
    "\n",
    "# Predictions\n",
    "cus_y_pred_valid = knn_cus.predict(X_valid_processed)\n",
    "cus_y_pred_test  = knn_cus.predict(X_test_processed)\n",
    "\n",
    "skl_y_pred_valid = knn_skl.predict(X_valid_processed)\n",
    "skl_y_pred_test  = knn_skl.predict(X_test_processed)\n",
    "\n",
    "# Accuracy\n",
    "cus_acc_valid = accuracy(encoded_y_valid, cus_y_pred_valid)\n",
    "cus_acc_test  = accuracy(encoded_y_test, cus_y_pred_test)\n",
    "\n",
    "skl_acc_valid = accuracy(encoded_y_valid, skl_y_pred_valid)\n",
    "skl_acc_test  = accuracy(encoded_y_test, skl_y_pred_test)\n",
    "\n",
    "# Print Results\n",
    "print('Custom  KNN Classifier Accuracy Valid:', cus_acc_valid)\n",
    "print('Custom  KNN Classifier Accuracy Test :', cus_acc_test)\n",
    "print()\n",
    "print('SKLearn KNN Classifier Accuracy Valid:', skl_acc_valid)\n",
    "print('SKLearn KNN Classifier Accuracy Test :', skl_acc_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom  SVM Classifier Accuracy Valid: 0.834\n",
      "Custom  SVM Classifier Accuracy Test : 0.842\n",
      "\n",
      "SKLearn SVM Classifier Accuracy Valid: 0.846\n",
      "SKLearn SVM Classifier Accuracy Test : 0.854\n"
     ]
    }
   ],
   "source": [
    "# Custom SVM Classifier\n",
    "svm_cus = SVM_Classifier(lambda_param=0.0001, learning_rate=0.001, num_of_iters=1000)\n",
    "svm_cus.fit(X_train_processed, encoded_y_train)\n",
    "\n",
    "# Sklearn SVM Classifier\n",
    "svm_skl = SVC() \n",
    "svm_skl.fit(X_train_processed, encoded_y_train)\n",
    "\n",
    "# Predictions\n",
    "cus_y_pred_valid = svm_cus.predict(X_valid_processed)\n",
    "cus_y_pred_test  = svm_cus.predict(X_test_processed)\n",
    "\n",
    "skl_y_pred_valid = svm_skl.predict(X_valid_processed)\n",
    "skl_y_pred_test  = svm_skl.predict(X_test_processed)\n",
    "\n",
    "# Accuracy\n",
    "cus_acc_valid = accuracy(encoded_y_valid, cus_y_pred_valid)\n",
    "cus_acc_test  = accuracy(encoded_y_test, cus_y_pred_test)\n",
    "\n",
    "skl_acc_valid = accuracy(encoded_y_valid, skl_y_pred_valid)\n",
    "skl_acc_test  = accuracy(encoded_y_test, skl_y_pred_test)\n",
    "\n",
    "# Print Results\n",
    "print('Custom  SVM Classifier Accuracy Valid:', cus_acc_valid)\n",
    "print('Custom  SVM Classifier Accuracy Test :', cus_acc_test)\n",
    "print()\n",
    "print('SKLearn SVM Classifier Accuracy Valid:', skl_acc_valid)\n",
    "print('SKLearn SVM Classifier Accuracy Test :', skl_acc_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom Decision Tree Classifier Accuracy Valid : 0.84\n",
      "Custom Decision Tree Classifier Accuracy Test  : 0.85\n",
      "\n",
      "SKLearn Decision Tree Classifier Accuracy Valid: 0.798\n",
      "SKLearn Decision Tree Classifier Accuracy Test : 0.834\n"
     ]
    }
   ],
   "source": [
    "# Custom Decision Tree Classifier\n",
    "dtr_cus = Decision_Tree_Classifier(min_samples_split=2, max_depth=5)\n",
    "dtr_cus.fit(X_train_processed, encoded_y_train)\n",
    "\n",
    "# Sklearn Decision Tree Classifier\n",
    "dtr_skl = DecisionTreeClassifier()\n",
    "dtr_skl.fit(X_train_processed, encoded_y_train)\n",
    "\n",
    "# Predictions\n",
    "cus_y_pred_valid = dtr_cus.predict(X_valid_processed)\n",
    "cus_y_pred_test  = dtr_cus.predict(X_test_processed)\n",
    "\n",
    "skl_y_pred_valid = dtr_skl.predict(X_valid_processed)\n",
    "skl_y_pred_test  = dtr_skl.predict(X_test_processed)\n",
    "\n",
    "# Accuracy\n",
    "cus_acc_valid = accuracy(encoded_y_valid, cus_y_pred_valid)\n",
    "cus_acc_test  = accuracy(encoded_y_test, cus_y_pred_test)\n",
    "\n",
    "skl_acc_valid = accuracy(encoded_y_valid, skl_y_pred_valid)\n",
    "skl_acc_test = accuracy(encoded_y_test, skl_y_pred_test)\n",
    "\n",
    "\n",
    "# Print Results\n",
    "print('Custom Decision Tree Classifier Accuracy Valid :', cus_acc_valid)\n",
    "print('Custom Decision Tree Classifier Accuracy Test  :', cus_acc_test)\n",
    "print()\n",
    "print('SKLearn Decision Tree Classifier Accuracy Valid:', skl_acc_valid)\n",
    "print('SKLearn Decision Tree Classifier Accuracy Test :', skl_acc_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom Random Forest Classifier Accuracy Valid : 0.846\n",
      "Custom Random Forest Classifier Accuracy Test  : 0.864\n",
      "\n",
      "SKLearn Random Forest Classifier Accuracy Valid: 0.832\n",
      "SKLearn Random Forest Classifier Accuracy Test : 0.848\n"
     ]
    }
   ],
   "source": [
    "# Custom Random Forest Classifier\n",
    "rfo_cus = Random_Forest_Classifier(n_trees=10, min_samples_split=2, max_depth=10)\n",
    "rfo_cus.fit(X_train_processed, encoded_y_train)\n",
    "\n",
    "# Sklearn Random Forest Classifier\n",
    "rfo_skl = RandomForestClassifier()\n",
    "rfo_skl.fit(X_train_processed, encoded_y_train)\n",
    "\n",
    "# Predictions\n",
    "cus_y_pred_valid = rfo_cus.predict(X_valid_processed)\n",
    "cus_y_pred_test  = rfo_cus.predict(X_test_processed)\n",
    "\n",
    "skl_y_pred_valid = rfo_skl.predict(X_valid_processed)\n",
    "skl_y_pred_test  = rfo_skl.predict(X_test_processed)\n",
    "\n",
    "# Accuracy\n",
    "cus_acc_valid = accuracy(encoded_y_valid, cus_y_pred_valid)\n",
    "cus_acc_test  = accuracy(encoded_y_test, cus_y_pred_test)\n",
    "\n",
    "skl_acc_valid = accuracy(encoded_y_valid, skl_y_pred_valid)\n",
    "skl_acc_test  = accuracy(encoded_y_test, skl_y_pred_test)\n",
    "\n",
    "# Print Results\n",
    "print('Custom Random Forest Classifier Accuracy Valid :', cus_acc_valid)\n",
    "print('Custom Random Forest Classifier Accuracy Test  :', cus_acc_test)\n",
    "print()\n",
    "print('SKLearn Random Forest Classifier Accuracy Valid:', skl_acc_valid)\n",
    "print('SKLearn Random Forest Classifier Accuracy Test :', skl_acc_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### AdaBoost "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nggar\\anaconda3\\envs\\FANDIS_VENV\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom AdaBoost Classifier Accuracy Valid : 0.832\n",
      "Custom AdaBoost Classifier Accuracy Test  : 0.854\n",
      "\n",
      "SKLearn AdaBoost Classifier Accuracy Valid: 0.836\n",
      "SKLearn AdaBoost Classifier Accuracy Test : 0.862\n"
     ]
    }
   ],
   "source": [
    "# Custom AdaBoost Classifier\n",
    "ada_cus = Adaboost_Classifier(n_clf=500)\n",
    "ada_cus.fit(X_train_processed, ab_encoded_y_train)\n",
    "\n",
    "# Sklearn AdaBoost Classifier\n",
    "ada_skl = AdaBoostClassifier()\n",
    "ada_skl.fit(X_train_processed, ab_encoded_y_train)\n",
    "\n",
    "# Predictions\n",
    "cus_y_pred_valid = ada_cus.predict(X_valid_processed)\n",
    "cus_y_pred_test  = ada_cus.predict(X_test_processed)\n",
    "\n",
    "skl_y_pred_valid = ada_skl.predict(X_valid_processed)\n",
    "skl_y_pred_test  = ada_skl.predict(X_test_processed)\n",
    "\n",
    "# Accuracy\n",
    "cus_acc_valid = accuracy(ab_encoded_y_valid, cus_y_pred_valid)\n",
    "cus_acc_test  = accuracy(ab_encoded_y_test, cus_y_pred_test)\n",
    "\n",
    "skl_acc_valid = accuracy(ab_encoded_y_valid, skl_y_pred_valid)\n",
    "skl_acc_test  = accuracy(ab_encoded_y_test, skl_y_pred_test)\n",
    "\n",
    "# Print Results\n",
    "print('Custom AdaBoost Classifier Accuracy Valid :', cus_acc_valid)\n",
    "print('Custom AdaBoost Classifier Accuracy Test  :', cus_acc_test)\n",
    "print()\n",
    "print('SKLearn AdaBoost Classifier Accuracy Valid:', skl_acc_valid)\n",
    "print('SKLearn AdaBoost Classifier Accuracy Test :', skl_acc_test)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FANDIS_VENV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
